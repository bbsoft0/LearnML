{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealJoker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3e81f522a4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# stratify - make sure classes are evenlly represented across splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "joker_data = pd.read_csv('./input/joker.csv')\n",
    "\n",
    "X = joker_data.copy()\n",
    "\n",
    "features_num = [\n",
    "    \"date\", \"avg\",\"idx\",\n",
    "]\n",
    "features_cat = [\n",
    "    \"weekd\", \"n1\", \"n2\",\n",
    "    \"n3\", \"n4\",\"n5\",\"j\",\n",
    "]\n",
    "\n",
    "transformer_num = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\"),  # there are a few missing values\n",
    "    StandardScaler(),\n",
    ")\n",
    "transformer_cat = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (transformer_num, features_num),\n",
    "    (transformer_cat, features_cat),\n",
    ")\n",
    "\n",
    "# stratify - make sure classes are evenlly represented across splits\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X, y, stratify=y, train_size=0.75)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# YOUR CODE HERE: define the model given in the diagram\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.4782 - binary_accuracy: 0.7730 - val_loss: 0.4334 - val_binary_accuracy: 0.8023\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.4205 - binary_accuracy: 0.8035 - val_loss: 0.4094 - val_binary_accuracy: 0.8114\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.4084 - binary_accuracy: 0.8090 - val_loss: 0.4001 - val_binary_accuracy: 0.8169\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 0.4001 - binary_accuracy: 0.8137 - val_loss: 0.3928 - val_binary_accuracy: 0.8182\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.3952 - binary_accuracy: 0.8164 - val_loss: 0.3887 - val_binary_accuracy: 0.8200\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.3909 - binary_accuracy: 0.8182 - val_loss: 0.3928 - val_binary_accuracy: 0.8207\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.3869 - binary_accuracy: 0.8190 - val_loss: 0.3869 - val_binary_accuracy: 0.8220\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.3845 - binary_accuracy: 0.8222 - val_loss: 0.3860 - val_binary_accuracy: 0.8238\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.3789 - binary_accuracy: 0.8248 - val_loss: 0.3799 - val_binary_accuracy: 0.8256\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.3774 - binary_accuracy: 0.8253 - val_loss: 0.3789 - val_binary_accuracy: 0.8266\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.3749 - binary_accuracy: 0.8263 - val_loss: 0.3776 - val_binary_accuracy: 0.8269\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.3733 - binary_accuracy: 0.8277 - val_loss: 0.3741 - val_binary_accuracy: 0.8284\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.3692 - binary_accuracy: 0.8292 - val_loss: 0.3737 - val_binary_accuracy: 0.8297\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.3675 - binary_accuracy: 0.8303 - val_loss: 0.3754 - val_binary_accuracy: 0.8286\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.3665 - binary_accuracy: 0.8314 - val_loss: 0.3685 - val_binary_accuracy: 0.8330\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.3658 - binary_accuracy: 0.8305 - val_loss: 0.3721 - val_binary_accuracy: 0.8301\n",
      "Epoch 17/200\n",
      "147/175 [========================>.....] - ETA: 0s - loss: 0.3627 - binary_accuracy: 0.8322"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(\n",
    "    title=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Though we can see the training loss continuing to fall, the early stopping callback prevented \n",
    "# any overfitting. Moreover, the accuracy rose at the same rate as the cross-entropy fell, so it appears\n",
    "#  that minimizing cross-entropy was a good stand-in. \n",
    "# All in all, it looks like this training was a success!\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
